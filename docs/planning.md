# üìò Plano de TCC ‚Äì ValorizeAI em Arquitetura Serverless Gerenciada no GCP

## üéØ Tema e Objetivos

**Tema:** Documentar e validar a escalabilidade e a alta disponibilidade do aplicativo financeiro **ValorizeAI** utilizando exclusivamente servi√ßos gerenciados do Google Cloud (Cloud Run, Cloud SQL, Memorystore, Cloud Tasks, Cloud Load Balancing).

**Objetivos espec√≠ficos**

1. Descrever a arquitetura completa do ValorizeAI destacando como cada servi√ßo gerenciado contribui para escalabilidade, seguran√ßa e observabilidade.
2. Definir SLOs vi√°veis (lat√™ncia, disponibilidade e throughput) e demonstrar, via experimentos, que o ValorizeAI consegue atingi-los.
3. Registrar o processo de implementa√ß√£o (Terraform + GitHub Actions/Cloud Build) e os testes de valida√ß√£o para que seja poss√≠vel reproduzir o ambiente a partir do reposit√≥rio atual.

**Perguntas de pesquisa**

* Qual √© a capacidade m√°xima (RPS) que a API em Cloud Run suporta antes de violar o SLO de lat√™ncia?
* Como a combina√ß√£o Cloud Run + Cloud SQL + Memorystore se comporta diante de falhas controladas (rein√≠cio da inst√¢ncia prim√°ria, indisponibilidade moment√¢nea do cache)?
* O pipeline ass√≠ncrono (Cloud Tasks ‚Üí Worker Cloud Run) mant√©m consist√™ncia e tempo de processamento adequado sob backlog ampliado?

> **Nota metodol√≥gica:** o foco √© demonstrar que o ValorizeAI, apoiado em servi√ßos gerenciados do GCP, cumpre os SLOs definidos. N√£o h√° pretens√£o de compar√°-lo com solu√ß√µes self-managed ou provar superioridade frente a outras clouds.

---

## ‚úÖ Premissas

* Workload HTTP/HTTPS com picos ocasionais (campanhas financeiras).
* Trilha de auditoria e consist√™ncia forte para transa√ß√µes cr√≠ticas.
* Requisitos de experi√™ncia em tempo real (notifica√ß√µes via Reverb/WebSockets).
* Equipe pequena (autor do TCC) com necessidade de produtividade alta ‚Üí foco em servi√ßos gerenciados para reduzir toil operacional.

**SLOs base**

| M√©trica                 | Valor alvo |
| ----------------------- | ---------- |
| Lat√™ncia P95 (API)      | ‚â§ 300 ms   |
| Erro percentual         | ‚â§ 0.5%     |
| Disponibilidade mensal  | ‚â• 99.5%    |
| MTTR falha planejada    | ‚â§ 60 s     |

*Limita√ß√£o pr√°tica:* todos os testes rodam com a cota padr√£o de uma conta nova do Cloud Run (m√°ximo de **10 inst√¢ncias**, cada uma com **1 vCPU / 1‚ÄØGiB**). Essa cota totaliza 10 vCPU dispon√≠veis para a carga e, durante os ensaios preliminares, resultou em satura√ß√£o pr√≥ximo de 900 RPS para os cen√°rios descritos. Esse valor √© uma observa√ß√£o emp√≠rica do nosso workload, n√£o um limite fixo do produto; os experimentos foram ajustados para explorar justamente o comportamento ao atingir o teto imposto pela cota.
---

## ‚òÅÔ∏è Arquitetura Proposta (Managed GCP)

### üîπ Edge / Rede

* **Cloud Load Balancing (HTTP(S))** com **Cloud CDN** e **Cloud Armor** (WAF/rate limit).
* Certificados gerenciados e roteamento custom domain (`valorizeai.*`).

### üîπ Aplica√ß√£o (Cloud Run)

| Servi√ßo                         | Plataforma        | Observa√ß√µes                                                                    |
| ------------------------------- | ----------------- | ------------------------------------------------------------------------------ |
| API Laravel                     | Cloud Run         | Stateless; concurrency 80; VPC Connector para acessar Cloud SQL/Memorystore.   |
| Laravel Reverb / WebSockets     | Cloud Run         | M√≠n 1 inst√¢ncia; escala horizontal; utiliza Memorystore como backend.          |
| Workers HTTP (Cloud Tasks)      | Cloud Run         | Endpoint privado recebe push das filas; idempot√™ncia via Redis/outbox.         |
| Jobs agendados                  | Cloud Run Jobs    | Disparados por Cloud Scheduler (cron di√°rios, limpeza, relat√≥rios).            |

### üîπ Dados e Cache

| Servi√ßo           | Uso principal                                          | Configura√ß√£o                                      |
| ----------------- | ------------------------------------------------------ | ------------------------------------------------- |
| **Cloud SQL (PostgreSQL)** | Banco transacional; prim√°ria + r√©plica de leitura (RO) | HA, backups autom√°ticos, TLS obrigat√≥rio.         |
| **Memorystore (Redis)**    | Cache, filas curtas, backend do Reverb            | Tier Standard; failover autom√°tico; VPC privada.  |
| **Cloud Storage**          | Uploads, relat√≥rios, snapshots de testes          | Bucket versionado com CMEK e TTL para tempor√°rios. |

### üîπ Mensageria / Processamento Ass√≠ncrono

* **Cloud Tasks**: filas por dom√≠nio (ex.: `payments`, `notifications`), com pol√≠tica de retry e DLQ (Pub/Sub) para observa√ß√£o.
* **Pub/Sub (opcional)**: usado apenas para broadcast de eventos que n√£o exigem confirma√ß√£o imediata (ex.: log de auditoria). Pode ser adiado se n√£o der tempo.

### üîπ Observabilidade

* **Cloud Monitoring + Logging + Trace** integrados via OpenTelemetry.
* Dashboards com m√©tricas-chave: lat√™ncia P95/P99, taxa de erro, consumo de Cloud SQL, conex√µes Redis, backlog Cloud Tasks.
* Alertas b√°sicos (lat√™ncia > 300 ms, backlog > 5k jobs, uso CPU Cloud SQL > 80%).

### üîπ Seguran√ßa

* IAM m√≠nimo necess√°rio, **Secret Manager** para segredos (creds DB, Resend, etc.).
* **VPC Connector** para Cloud Run ‚Üí Cloud SQL/Memorystore.
* Auditoria via Cloud Audit Logs.

### üîπ Infraestrutura como C√≥digo

```
terraform/
  main.tf                      # m√≥dulos cloudrun, load balancer, secrets
  modules/
    cloudrun/
    load-balancer/
  ...
```

* Terraform existente continuar√° sendo usado; ajustes focam em parametrizar Cloud SQL/Memorystore (provisionados fora do repo ou via m√≥dulos simples).
* Pipeline: GitHub Actions ‚Üí build container ‚Üí deploy Cloud Run ‚Üí execu√ß√£o de smoke tests.

---

## üß† Hip√≥teses e Testes

### Hip√≥teses

1. **Escalabilidade da API Cloud Run**  
   * **H‚ÇÄ‚ÇÅ:** Antes de esgotar a cota atual (10 inst√¢ncias de 1‚ÄØvCPU / 1‚ÄØGiB), a lat√™ncia P95 excede 300 ms ou a taxa de erros passa de 0,5%.  
   * **H‚ÇÅ‚ÇÅ:** Enquanto houver vCPU dispon√≠vel dentro dessa cota (observada em torno de 900 RPS para este workload), a API mant√©m os SLOs.
2. **Resili√™ncia do plano de dados**  
   * **H‚ÇÄ‚ÇÇ:** Falhas controladas (failover Cloud SQL, reset de Memorystore) causam indisponibilidade > 60 s ou perda de requisi√ß√µes.  
   * **H‚ÇÅ‚ÇÇ:** O app se recupera em < 60 s e mant√©m consist√™ncia.
3. **Processamento ass√≠ncrono (Cloud Tasks)**  
   * **H‚ÇÄ‚ÇÉ:** Um backlog 10√ó maior n√£o √© drenado em < 5 min ou gera duplicidade de jobs.  
   * **H‚ÇÅ‚ÇÉ:** O worker Cloud Run processa o backlog com idempot√™ncia e dentro do tempo alvo.
4. **Observabilidade/Custo b√°sico**  
   * **H‚ÇÄ‚ÇÑ:** Durante os testes, n√£o h√° dados suficientes para provar SLOs ou o custo extrapola o or√ßamento definido.  
   * **H‚ÇÅ‚ÇÑ:** Os dashboards capturam todas as m√©tricas necess√°rias e o custo permanece dentro do planejado.

### Matriz de testes

| # | Hip√≥tese | Objetivo                        | Cen√°rio / Procedimento                                                                 | M√©tricas principais                             | Ferramentas                                  | Crit√©rio de sucesso                                      |
| - | -------- | ------------------------------- | -------------------------------------------------------------------------------------- | ----------------------------------------------- | -------------------------------------------- | -------------------------------------------------------- |
| 1 | H‚ÇÄ‚ÇÅ vs H‚ÇÅ‚ÇÅ | Escalabilidade da API          | k6 com ramp-up progressivo at√© saturar a cota (10 inst√¢ncias / ~10‚ÄØvCPU), atingindo ‚âà900 RPS para este workload | Lat√™ncia P95, P99, throughput, erro %            | k6 + Cloud Monitoring                        | P95 ‚â§ 300 ms, erro % ‚â§ 0.5 enquanto houver vCPU dispon√≠vel na cota atual                  |
| 2 | H‚ÇÄ‚ÇÇ vs H‚ÇÅ‚ÇÇ | Falha em Cloud SQL / Redis     | For√ßar failover manual no Cloud SQL + reiniciar Memorystore                            | MTTR, erro %, n√∫mero de reconex√µes              | gcloud sql failover, Cloud Monitoring         | MTTR ‚â§ 60 s, erro % < 1%, aplica√ß√£o retoma conex√µes      |
| 3 | H‚ÇÄ‚ÇÉ vs H‚ÇÅ‚ÇÉ | Backlog Cloud Tasks            | Injetar 10√ó jobs (ex.: 10k notifica√ß√µes), suspender/retomar worker Cloud Run           | Tempo para zerar fila, jobs DLQ, duplicidade    | Cloud Tasks metrics, Cloud Logging            | Backlog drenado ‚â§ 5 min, DLQ ‚â§ 0.5%, duplicidade inexistente |
| 4 | H‚ÇÄ‚ÇÑ vs H‚ÇÅ‚ÇÑ | Observabilidade/Custo          | Revisar dashboards/alertas durante testes + estimar custo di√°rio (Billing export)      | M√©tricas coletadas, custo por 1k req            | Cloud Monitoring, Billing Export ‚Üí BigQuery  | Todas as m√©tricas coletadas + custo dentro do or√ßamento  |

---

## ‚úçÔ∏è Estrutura Proposta do TCC

1. **Introdu√ß√£o** ‚Äì Contexto do ValorizeAI, problema, objetivos e perguntas de pesquisa.  
2. **Trabalhos Relacionados** ‚Äì Aborda arquiteturas serverless em nuvem, refer√™ncias sobre Cloud Run/Cloud SQL.  
3. **Fundamenta√ß√£o Te√≥rica** ‚Äì Conceitos de serverless, filas ass√≠ncronas, SLO/SLA, observabilidade.  
4. **Produto ValorizeAI** ‚Äì Personas, fluxos cr√≠ticos, requisitos funcionais/n√£o funcionais.  
5. **Arquitetura Serverless no GCP** ‚Äì Descri√ß√£o detalhada dos servi√ßos usados, diagramas e justificativas.  
6. **Metodologia e Plano Experimental** ‚Äì Ambientes, ferramentas, scripts e hip√≥teses.  
7. **Implementa√ß√£o e Infraestrutura** ‚Äì Terraform, pipeline CI/CD, configura√ß√µes da aplica√ß√£o.  
8. **Experimentos e Resultados** ‚Äì Execu√ß√£o dos testes 1‚Äì4, an√°lise dos dados, aceita√ß√£o/rejei√ß√£o das hip√≥teses.  
9. **Discuss√£o e Limita√ß√µes** ‚Äì Li√ß√µes aprendidas, riscos, poss√≠veis otimiza√ß√µes futuras (ex.: GKE).  
10. **Conclus√£o** ‚Äì Resumo das contribui√ß√µes e recomenda√ß√µes.

---

## üóìÔ∏è Cronograma (3 semanas)

| Semana | Foco                                 | Detalhes                                                                 |
| ------ | ------------------------------------ | ------------------------------------------------------------------------ |
| 1      | Infra & Documenta√ß√£o                  | Ajustar Terraform existente, provisionar Cloud SQL/Memorystore, atualizar docs, iniciar cap√≠tulos 1‚Äì5. |
| 2      | Testes & Observabilidade              | Configurar k6, scripts de failover, dashboards; rodar testes 1 e 2; escrever cap√≠tulos 6‚Äì8 (parcial). |
| 3      | Processamento ass√≠ncrono + Escrita    | Rodar teste 3 e 4, consolidar resultados, finalizar cap√≠tulos 8‚Äì10, revis√£o geral. |

---

## üí° Pr√≥ximos Passos

1. Atualizar Terraform para parametrizar Cloud SQL/Memorystore (ou documentar provisioning manual caso j√° existam).  
2. Garantir que Cloud Run (API + workers) esteja usando segredos do Secret Manager e conectores VPC.  
3. Preparar scripts de teste (k6, failover, inje√ß√£o Cloud Tasks) e dashboards no Cloud Monitoring.  
4. Iniciar a escrita dos cap√≠tulos 1‚Äì5 usando este documento como guia, incrementando conforme testes avan√ßarem.

---

## üß™ Plano de Testes com k6

### Objetivos

1. Validar os SLOs definidos (lat√™ncia P95 ‚â§ 300‚ÄØms, erro ‚â§ 0,5%) para as rotas cr√≠ticas da API.  
2. Medir a capacidade m√°xima de RPS sustentado em Cloud Run antes de violar os SLOs.  
3. Obter insumos para o cap√≠tulo de ‚ÄúExperimentos e Resultados‚Äù (gr√°ficos, tabelas, logs).

### Escopo Inicial

| Cen√°rio | Rota / Fluxo                                                | Objetivo principal                                            | Dura√ß√£o | Carga alvo (Stg ‚Üí Prod ‚Üí Stress) |
| ------- | ----------------------------------------------------------- | ------------------------------------------------------------- | ------- | ------------------------------- |
| C1      | `GET /api/transactions` com filtros variados                | Exercitar filtros (contas, categorias, datas, tipo, ordena√ß√£o) | 10 min  | 50‚Üí150 ‚Üí **300** ‚Üí est√°gio de satura√ß√£o (‚âà900 RPS observados)  |
| C2      | `POST /api/transactions` com dados aleat√≥rios               | Validar cria√ß√£o massiva com datas/passado e recursos distintos | 15 min  | 25‚Üí80 ‚Üí **200** ‚Üí **600** RPS   |
| C3      | Mix (65% `GET /api/transactions`, 20% `POST /api/transactions`, 15% `GET /api/accounts`) | Emular tr√°fego realista combinando leitura e escrita           | 18 min  | 30‚Üí100 ‚Üí **250** ‚Üí **700** RPS  |

> Ajustar rotas conforme os novos controladores API. Ambientes de staging come√ßam com as cargas menores; em produ√ß√£o, as fases finais devem atingir as metas em negrito.  
> Ap√≥s cumprir os SLOs em 300/200/250 RPS, o **stress** sobe gradualmente at√© esgotar a cota atual (10 inst√¢ncias de 1‚ÄØvCPU / 1‚ÄØGiB). Com o nosso workload, isso ocorreu pr√≥ximo de 900 RPS; pequenos spikes acima desse valor servem apenas para registrar o ponto de satura√ß√£o.  
> O cen√°rio C3 mant√©m a propor√ß√£o 65/20/15 para refletir o mix dominante de leituras. Ap√≥s 700‚ÄØRPS, um spike curto de ~850‚ÄØRPS √© usado apenas para indicar o ponto de satura√ß√£o.

### Estrat√©gia para sustentar o limite de cota (‚âà900 RPS no nosso workload)

1. **Ramp progressivo** ‚Äì repetir cada cen√°rio em tr√™s fases (baseline, produ√ß√£o, stress). O stress aumenta os VUs at√© que o k6 reporte satura√ß√£o da cota (‚âà900 RPS neste ambiente), registrando o comportamento logo antes do esgotamento das vCPU.
2. **Afinar Cloud Run dentro da cota** ‚Äì manter `concurrency = 80` e `max-instances = 10`, monitorando CPU/mem√≥ria para justificar por que n√£o √© poss√≠vel subir para inst√¢ncias maiores (quota).  
3. **Observabilidade focada** ‚Äì habilitar gr√°ficos espec√≠ficos (lat√™ncia P95/P99, CPU, conex√µes DB, cache hit) para correlacionar o ponto em que o SLO √© quebrado e registrar a limita√ß√£o de recursos.  
4. **Stress controlado** ‚Äì executar um ‚Äúoverload‚Äù curto (at√© 1.000 RPS) apenas para comprovar onde os SLOs passam a ser violados, consolidando o argumento de limita√ß√£o por quota.

### Organiza√ß√£o do Projeto k6

```
tests/k6/
  README.md                  # instru√ß√µes de execu√ß√£o
  env.example                # vari√°veis (BASE_URL, TOKEN, etc.)
  scenarios/
    accounts.js
    transactions.js
    mix.js
  helpers/
    auth.js                  # fun√ß√£o para obter token via Sanctum
    metrics.js               # registradores customizados
```

### Estrutura de Script (exemplo)

```js
import http from 'k6/http';
import { sleep, check } from 'k6';

export const options = {
  stages: [
    { duration: '2m', target: 50 },
    { duration: '5m', target: 150 },
    { duration: '3m', target: 0 },
  ],
  thresholds: {
    http_req_duration: ['p(95)<300'],
    http_req_failed: ['rate<0.005'],
  },
};

export default function () {
  const res = http.get(`${__ENV.BASE_URL}/api/accounts`, {
    headers: { Authorization: `Bearer ${__ENV.TOKEN}` },
  });

  check(res, {
    'status 200': (r) => r.status === 200,
  });

  sleep(1);
}
```

### üìà Coleta de m√©tricas (Cloud Run / Cloud SQL)

1. **Marque o intervalo do teste**

```bash
TEST_START="$(date -Iseconds)"   # antes de iniciar o k6
# ... roda o k6 ...
TEST_END="$(date -Iseconds)"     # logo ap√≥s o t√©rmino
echo "$TEST_START ‚Üí $TEST_END"
```

2. **Cloud Run**

| M√©trica                                           | Descri√ß√£o                        |
| ------------------------------------------------- | -------------------------------- |
| `run.googleapis.com/request_latencies`            | Lat√™ncia P95/P99                  |
| `run.googleapis.com/request_count`                | Throughput                        |
| `run.googleapis.com/container/instance_count`     | Inst√¢ncias ativas                 |
| `run.googleapis.com/container/cpu.utilization`    | Uso de CPU por inst√¢ncia          |
| `run.googleapis.com/container/memory.utilization` | Uso de mem√≥ria por inst√¢ncia      |

```bash
# P95 durante o intervalo
gcloud monitoring time-series list \
  --filter='metric.type="run.googleapis.com/request_latencies"
            AND resource.labels.service_name="valorizeai"' \
  --interval-start="$TEST_START" \
  --interval-end="$TEST_END"

# Contagem de inst√¢ncias
gcloud monitoring time-series list \
  --filter='metric.type="run.googleapis.com/container/instance_count"
            AND resource.labels.service_name="valorizeai"' \
  --interval-start="$TEST_START" \
  --interval-end="$TEST_END"
```

3. **Cloud SQL**

| M√©trica                                                | Descri√ß√£o             |
| ------------------------------------------------------ | --------------------- |
| `cloudsql.googleapis.com/database/cpu/utilization`     | Uso de CPU            |
| `cloudsql.googleapis.com/database/memory/utilization`  | Uso de mem√≥ria        |
| `cloudsql.googleapis.com/database/connection/count`    | Conex√µes ativas       |

```bash
gcloud monitoring time-series list \
  --filter='metric.type="cloudsql.googleapis.com/database/cpu/utilization"
            AND resource.labels.database_id="valorizeai-db"' \
  --interval-start="$TEST_START" \
  --interval-end="$TEST_END"

gcloud monitoring time-series list \
  --filter='metric.type="cloudsql.googleapis.com/database/connection/count"
            AND resource.labels.database_id="valorizeai-db"' \
  --interval-start="$TEST_START" \
  --interval-end="$TEST_END"
```

4. **Dashboard/Tabelas**

- Monte um dashboard no Cloud Monitoring com os gr√°ficos acima (P95, inst√¢ncias, CPU/mem√≥ria, conex√µes SQL) e exporte para usar como figuras no TCC.
- Gere uma tabela por cen√°rio com: fase (RPS alvo), P95 (ms), erro (%), inst√¢ncias Cloud Run, CPU/mem√≥ria, CPU Cloud SQL, conex√µes. Use os valores coletados via CLI ou dashboard.

### üìë Como registrar os resultados no TCC

1. **Metodologia por cen√°rio** ‚Äì para cada C1/C2/C3 descreva o script (ramp-up, propor√ß√£o das rotas, ambiente Cloud Run com 1‚ÄØvCPU/1‚ÄØGiB e `max-instances = 10`). Explique que o limite observado decorre da cota de 10 vCPU (aproximadamente 900‚ÄØRPS no nosso workload) e n√£o de uma trava intr√≠nseca do servi√ßo.
2. **Tabelas resumidas** ‚Äì crie uma tabela por cen√°rio com colunas: *Fase* (150, 300, 600, 900‚ÄØRPS‚Ä¶), *P95 (ms)*, *Erro (%)*, *CPU Cloud Run (%)*, *Conex√µes Cloud SQL*, *Observa√ß√µes*. Use dados do k6 + Cloud Monitoring. Destaque em negrito a linha onde os SLOs come√ßam a ser violados.
3. **Gr√°ficos** ‚Äì insira dois gr√°ficos por cen√°rio:  
   - **Lat√™ncia P95 vs. RPS** (eixo X = RPS alvo, eixo Y = P95).  
   - **Throughput/erros ao longo do tempo** (print do dashboard ou gr√°fico exportado do k6).  
   Substitua ‚Äú2k RPS‚Äù por ‚Äú900‚ÄØRPS‚Äù nos t√≠tulos e mencione o spike de 1‚ÄØ000‚ÄØRPS apenas como stress adicional.
4. **Texto anal√≠tico** ‚Äì para cada cen√°rio escreva um par√°grafo seguindo o template:  
   *‚ÄúNo cen√°rio C1 (GET /api/transactions), o servi√ßo manteve P95 ‚â§ 210‚ÄØms e erros <0,5% at√© o esgotamento da cota (‚âà900‚ÄØRPS). Ao for√ßar 1‚ÄØ000‚ÄØRPS, observou-se aumento para 320‚ÄØms e 1,2% de erros, confirmando que o limite atual decorre da cota de inst√¢ncias (10 √ó 1‚ÄØvCPU/1‚ÄØGiB).‚Äù*  
   Fa√ßa refer√™ncia cruzada √†s Figuras/Tabelas e discuta como isso valida ou refuta H‚ÇÄ‚ÇÅ/H‚ÇÅ‚ÇÅ.
5. **S√≠ntese na discuss√£o** ‚Äì no cap√≠tulo de discuss√£o, explique que, apesar de o objetivo inicial prever 2k‚ÄØRPS, o ambiente real ficou limitado pela cota padr√£o (10 vCPU). Justifique por que trabalhar at√© esse limite observado (~900‚ÄØRPS) √© suficiente para o escopo do TCC e aponte trabalhos futuros (ex.: solicitar mais quota ou usar Cloud Run CPU Always On).

### Vari√°veis e Segredos

| Vari√°vel      | Descri√ß√£o                                | Origem                         |
| ------------- | ---------------------------------------- | ------------------------------ |
| `BASE_URL`    | URL p√∫blica do Cloud Run / Load Balancer | `.env` local ou Secret Manager |
| `TOKEN`       | Token gerado via `/api/tokens`           | Criar usu√°rio de teste         |
| `ACCOUNT_ID`  | ID fixo para cen√°rios POST               | Preenchido via script setup    |

No `README` incluir instru√ß√µes para gerar o token automaticamente (ex.: rodar `php artisan user:token` ou chamar endpoint de login via script `setup()` no k6).

### Execu√ß√£o

```bash
cd tests/k6
cp env.example .env          # preencher valores
export $(xargs < .env)
k6 run scenarios/accounts.js
```

Para execu√ß√µes automatizadas (CI/CD ou Cloud Build), usar `k6 run --out cloud` ou integrar com o k6 Cloud se houver licen√ßa. Tamb√©m registrar m√©tricas no Cloud Monitoring via `otel collector` (opcional).

### Coleta e An√°lise

* Armazenar o CSV de resultados (`k6 run --out csv=out/accounts.csv`).  
* Gerar gr√°ficos a partir do CSV (Planilha ou Grafana).  
* Comparar P95/P99 com os SLOs e documentar no cap√≠tulo de resultados.  
* Correlacionar com logs do Cloud Run / Cloud Monitoring (ex.: screenshot de dashboard de CPU/RPS durante o teste).

### Pr√≥ximos Passos Espec√≠ficos

1. Criar diret√≥rio `tests/k6` seguindo a estrutura proposta.  
2. Escrever `README.md` com preparo de ambiente (Credenciais, Base URL, gera√ß√£o de token).  
3. Implementar o primeiro cen√°rio (C1) e executar contra ambiente de staging.  
4. Registrar m√©tricas e ajustar thresholds antes de rodar os demais cen√°rios.  
5. Automatizar a coleta (CSV + dashboards) para uso no TCC.
