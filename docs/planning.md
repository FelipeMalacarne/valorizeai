# üìò Plano de TCC ‚Äì ValorizeAI em Arquitetura Serverless Gerenciada no GCP

## üéØ Tema e Objetivos

**Tema:** Documentar e validar a escalabilidade e a alta disponibilidade do aplicativo financeiro **ValorizeAI** utilizando exclusivamente servi√ßos gerenciados do Google Cloud (Cloud Run, Cloud SQL, Memorystore, Cloud Tasks, Cloud Load Balancing).

**Objetivos espec√≠ficos**

1. Descrever a arquitetura completa do ValorizeAI destacando como cada servi√ßo gerenciado contribui para escalabilidade, seguran√ßa e observabilidade.
2. Definir SLOs vi√°veis (lat√™ncia, disponibilidade e throughput) e demonstrar, via experimentos, que o ValorizeAI consegue atingi-los.
3. Registrar o processo de implementa√ß√£o (Terraform + GitHub Actions/Cloud Build) e os testes de valida√ß√£o para que seja poss√≠vel reproduzir o ambiente a partir do reposit√≥rio atual.

**Perguntas de pesquisa**

* Qual √© a capacidade m√°xima (RPS) que a API em Cloud Run suporta antes de violar o SLO de lat√™ncia?
* Como a combina√ß√£o Cloud Run + Cloud SQL + Memorystore se comporta diante de falhas controladas (rein√≠cio da inst√¢ncia prim√°ria, indisponibilidade moment√¢nea do cache)?
* O pipeline ass√≠ncrono (Cloud Tasks ‚Üí Worker Cloud Run) mant√©m consist√™ncia e tempo de processamento adequado sob backlog ampliado?

> **Nota metodol√≥gica:** o foco √© demonstrar que o ValorizeAI, apoiado em servi√ßos gerenciados do GCP, cumpre os SLOs definidos. N√£o h√° pretens√£o de compar√°-lo com solu√ß√µes self-managed ou provar superioridade frente a outras clouds.

---

## ‚úÖ Premissas

* Workload HTTP/HTTPS com picos ocasionais (campanhas financeiras).
* Trilha de auditoria e consist√™ncia forte para transa√ß√µes cr√≠ticas.
* Requisitos de experi√™ncia em tempo real (notifica√ß√µes via Reverb/WebSockets).
* Equipe pequena (autor do TCC) com necessidade de produtividade alta ‚Üí foco em servi√ßos gerenciados para reduzir toil operacional.

**SLOs base**

| M√©trica                 | Valor alvo |
| ----------------------- | ---------- |
| Lat√™ncia P95 (API)      | ‚â§ 250 ms   |
| Erro percentual         | ‚â§ 0.5%     |
| Disponibilidade mensal  | ‚â• 99.5%    |
| MTTR falha planejada    | ‚â§ 60 s     |

---

## ‚òÅÔ∏è Arquitetura Proposta (Managed GCP)

### üîπ Edge / Rede

* **Cloud Load Balancing (HTTP(S))** com **Cloud CDN** e **Cloud Armor** (WAF/rate limit).
* Certificados gerenciados e roteamento custom domain (`valorizeai.*`).

### üîπ Aplica√ß√£o (Cloud Run)

| Servi√ßo                         | Plataforma        | Observa√ß√µes                                                                    |
| ------------------------------- | ----------------- | ------------------------------------------------------------------------------ |
| API Laravel                     | Cloud Run         | Stateless; concurrency 80; VPC Connector para acessar Cloud SQL/Memorystore.   |
| Laravel Reverb / WebSockets     | Cloud Run         | M√≠n 1 inst√¢ncia; escala horizontal; utiliza Memorystore como backend.          |
| Workers HTTP (Cloud Tasks)      | Cloud Run         | Endpoint privado recebe push das filas; idempot√™ncia via Redis/outbox.         |
| Jobs agendados                  | Cloud Run Jobs    | Disparados por Cloud Scheduler (cron di√°rios, limpeza, relat√≥rios).            |

### üîπ Dados e Cache

| Servi√ßo           | Uso principal                                          | Configura√ß√£o                                      |
| ----------------- | ------------------------------------------------------ | ------------------------------------------------- |
| **Cloud SQL (PostgreSQL)** | Banco transacional; prim√°ria + r√©plica de leitura (RO) | HA, backups autom√°ticos, TLS obrigat√≥rio.         |
| **Memorystore (Redis)**    | Cache, filas curtas, backend do Reverb            | Tier Standard; failover autom√°tico; VPC privada.  |
| **Cloud Storage**          | Uploads, relat√≥rios, snapshots de testes          | Bucket versionado com CMEK e TTL para tempor√°rios. |

### üîπ Mensageria / Processamento Ass√≠ncrono

* **Cloud Tasks**: filas por dom√≠nio (ex.: `payments`, `notifications`), com pol√≠tica de retry e DLQ (Pub/Sub) para observa√ß√£o.
* **Pub/Sub (opcional)**: usado apenas para broadcast de eventos que n√£o exigem confirma√ß√£o imediata (ex.: log de auditoria). Pode ser adiado se n√£o der tempo.

### üîπ Observabilidade

* **Cloud Monitoring + Logging + Trace** integrados via OpenTelemetry.
* Dashboards com m√©tricas-chave: lat√™ncia P95/P99, taxa de erro, consumo de Cloud SQL, conex√µes Redis, backlog Cloud Tasks.
* Alertas b√°sicos (lat√™ncia > 250 ms, backlog > 5k jobs, uso CPU Cloud SQL > 80%).

### üîπ Seguran√ßa

* IAM m√≠nimo necess√°rio, **Secret Manager** para segredos (creds DB, Resend, etc.).
* **VPC Connector** para Cloud Run ‚Üí Cloud SQL/Memorystore.
* Auditoria via Cloud Audit Logs.

### üîπ Infraestrutura como C√≥digo

```
terraform/
  main.tf                      # m√≥dulos cloudrun, load balancer, secrets
  modules/
    cloudrun/
    load-balancer/
  ...
```

* Terraform existente continuar√° sendo usado; ajustes focam em parametrizar Cloud SQL/Memorystore (provisionados fora do repo ou via m√≥dulos simples).
* Pipeline: GitHub Actions ‚Üí build container ‚Üí deploy Cloud Run ‚Üí execu√ß√£o de smoke tests.

---

## üß† Hip√≥teses e Testes

### Hip√≥teses

1. **Escalabilidade da API Cloud Run**  
   * **H‚ÇÄ‚ÇÅ:** Antes de atingir 2k RPS, a lat√™ncia P95 excede 250 ms ou a taxa de erros passa de 0,5%.  
   * **H‚ÇÅ‚ÇÅ:** A API mant√©m os SLOs at√© 2k RPS.
2. **Resili√™ncia do plano de dados**  
   * **H‚ÇÄ‚ÇÇ:** Falhas controladas (failover Cloud SQL, reset de Memorystore) causam indisponibilidade > 60 s ou perda de requisi√ß√µes.  
   * **H‚ÇÅ‚ÇÇ:** O app se recupera em < 60 s e mant√©m consist√™ncia.
3. **Processamento ass√≠ncrono (Cloud Tasks)**  
   * **H‚ÇÄ‚ÇÉ:** Um backlog 10√ó maior n√£o √© drenado em < 5 min ou gera duplicidade de jobs.  
   * **H‚ÇÅ‚ÇÉ:** O worker Cloud Run processa o backlog com idempot√™ncia e dentro do tempo alvo.
4. **Observabilidade/Custo b√°sico**  
   * **H‚ÇÄ‚ÇÑ:** Durante os testes, n√£o h√° dados suficientes para provar SLOs ou o custo extrapola o or√ßamento definido.  
   * **H‚ÇÅ‚ÇÑ:** Os dashboards capturam todas as m√©tricas necess√°rias e o custo permanece dentro do planejado.

### Matriz de testes

| # | Hip√≥tese | Objetivo                        | Cen√°rio / Procedimento                                                                 | M√©tricas principais                             | Ferramentas                                  | Crit√©rio de sucesso                                      |
| - | -------- | ------------------------------- | -------------------------------------------------------------------------------------- | ----------------------------------------------- | -------------------------------------------- | -------------------------------------------------------- |
| 1 | H‚ÇÄ‚ÇÅ vs H‚ÇÅ‚ÇÅ | Escalabilidade da API          | k6/Locust gerando ramp-up 0‚Üí2k RPS na rota `/api/v1/...`; Cloud Run escalando at√© limite | Lat√™ncia P95, P99, throughput, erro %            | k6 + Cloud Monitoring                        | P95 ‚â§ 250 ms, erro % ‚â§ 0.5 at√© 2k RPS                    |
| 2 | H‚ÇÄ‚ÇÇ vs H‚ÇÅ‚ÇÇ | Falha em Cloud SQL / Redis     | For√ßar failover manual no Cloud SQL + reiniciar Memorystore                            | MTTR, erro %, n√∫mero de reconex√µes              | gcloud sql failover, Cloud Monitoring         | MTTR ‚â§ 60 s, erro % < 1%, aplica√ß√£o retoma conex√µes      |
| 3 | H‚ÇÄ‚ÇÉ vs H‚ÇÅ‚ÇÉ | Backlog Cloud Tasks            | Injetar 10√ó jobs (ex.: 10k notifica√ß√µes), suspender/retomar worker Cloud Run           | Tempo para zerar fila, jobs DLQ, duplicidade    | Cloud Tasks metrics, Cloud Logging            | Backlog drenado ‚â§ 5 min, DLQ ‚â§ 0.5%, duplicidade inexistente |
| 4 | H‚ÇÄ‚ÇÑ vs H‚ÇÅ‚ÇÑ | Observabilidade/Custo          | Revisar dashboards/alertas durante testes + estimar custo di√°rio (Billing export)      | M√©tricas coletadas, custo por 1k req            | Cloud Monitoring, Billing Export ‚Üí BigQuery  | Todas as m√©tricas coletadas + custo dentro do or√ßamento  |

---

## ‚úçÔ∏è Estrutura Proposta do TCC

1. **Introdu√ß√£o** ‚Äì Contexto do ValorizeAI, problema, objetivos e perguntas de pesquisa.  
2. **Trabalhos Relacionados** ‚Äì Aborda arquiteturas serverless em nuvem, refer√™ncias sobre Cloud Run/Cloud SQL.  
3. **Fundamenta√ß√£o Te√≥rica** ‚Äì Conceitos de serverless, filas ass√≠ncronas, SLO/SLA, observabilidade.  
4. **Produto ValorizeAI** ‚Äì Personas, fluxos cr√≠ticos, requisitos funcionais/n√£o funcionais.  
5. **Arquitetura Serverless no GCP** ‚Äì Descri√ß√£o detalhada dos servi√ßos usados, diagramas e justificativas.  
6. **Metodologia e Plano Experimental** ‚Äì Ambientes, ferramentas, scripts e hip√≥teses.  
7. **Implementa√ß√£o e Infraestrutura** ‚Äì Terraform, pipeline CI/CD, configura√ß√µes da aplica√ß√£o.  
8. **Experimentos e Resultados** ‚Äì Execu√ß√£o dos testes 1‚Äì4, an√°lise dos dados, aceita√ß√£o/rejei√ß√£o das hip√≥teses.  
9. **Discuss√£o e Limita√ß√µes** ‚Äì Li√ß√µes aprendidas, riscos, poss√≠veis otimiza√ß√µes futuras (ex.: GKE).  
10. **Conclus√£o** ‚Äì Resumo das contribui√ß√µes e recomenda√ß√µes.

---

## üóìÔ∏è Cronograma (3 semanas)

| Semana | Foco                                 | Detalhes                                                                 |
| ------ | ------------------------------------ | ------------------------------------------------------------------------ |
| 1      | Infra & Documenta√ß√£o                  | Ajustar Terraform existente, provisionar Cloud SQL/Memorystore, atualizar docs, iniciar cap√≠tulos 1‚Äì5. |
| 2      | Testes & Observabilidade              | Configurar k6, scripts de failover, dashboards; rodar testes 1 e 2; escrever cap√≠tulos 6‚Äì8 (parcial). |
| 3      | Processamento ass√≠ncrono + Escrita    | Rodar teste 3 e 4, consolidar resultados, finalizar cap√≠tulos 8‚Äì10, revis√£o geral. |

---

## üí° Pr√≥ximos Passos

1. Atualizar Terraform para parametrizar Cloud SQL/Memorystore (ou documentar provisioning manual caso j√° existam).  
2. Garantir que Cloud Run (API + workers) esteja usando segredos do Secret Manager e conectores VPC.  
3. Preparar scripts de teste (k6, failover, inje√ß√£o Cloud Tasks) e dashboards no Cloud Monitoring.  
4. Iniciar a escrita dos cap√≠tulos 1‚Äì5 usando este documento como guia, incrementando conforme testes avan√ßarem.

---

## üß™ Plano de Testes com k6

### Objetivos

1. Validar os SLOs definidos (lat√™ncia P95 ‚â§ 250‚ÄØms, erro ‚â§ 0,5%) para as rotas cr√≠ticas da API.  
2. Medir a capacidade m√°xima de RPS sustentado em Cloud Run antes de violar os SLOs.  
3. Obter insumos para o cap√≠tulo de ‚ÄúExperimentos e Resultados‚Äù (gr√°ficos, tabelas, logs).

### Escopo Inicial

| Cen√°rio | Rota / Fluxo                                                | Objetivo principal                            | Dura√ß√£o | Carga alvo (Stg ‚Üí Prod) |
| ------- | ----------------------------------------------------------- | --------------------------------------------- | ------- | ----------------------- |
| C1      | `POST /api/token` (login) + `GET /api/accounts`             | Medir lat√™ncia de autentica√ß√£o + listagem     | 10 min  | 50‚Üí150 ‚Üí **400** RPS    |
| C2      | `POST /api/transactions`                                    | Validar cria√ß√£o de transa√ß√µes sob pico        | 15 min  | 25‚Üí120 ‚Üí **300** RPS    |
| C3      | `GET /api/dashboard` (ou `/dashboard` SSR)                  | Observar endpoints mais pesados de leitura    | 15 min  | 10‚Üí60 ‚Üí **120** RPS     |
| C4      | Mix (50% `GET /api/transactions`, 30% `POST /api/transactions`, 20% `GET /api/accounts`) | Emular tr√°fego realista com mix read/write | 20 min  | 30‚Üí100 ‚Üí **350** RPS    |

> Ajustar rotas conforme os novos controladores API. Ambientes de staging come√ßam com as cargas menores; em produ√ß√£o, as fases finais devem atingir as metas em negrito.  
> O cen√°rio C4 garante metade do tr√°fego em `GET /api/transactions` e a outra metade dividida entre `POST /api/transactions` e `GET /api/accounts`, cobrindo leitura e escrita no mesmo dom√≠nio.

### Organiza√ß√£o do Projeto k6

```
tests/k6/
  README.md                  # instru√ß√µes de execu√ß√£o
  env.example                # vari√°veis (BASE_URL, TOKEN, etc.)
  scenarios/
    accounts.js
    transactions.js
    mix.js
  helpers/
    auth.js                  # fun√ß√£o para obter token via Sanctum
    metrics.js               # registradores customizados
```

### Estrutura de Script (exemplo)

```js
import http from 'k6/http';
import { sleep, check } from 'k6';

export const options = {
  stages: [
    { duration: '2m', target: 50 },
    { duration: '5m', target: 150 },
    { duration: '3m', target: 0 },
  ],
  thresholds: {
    http_req_duration: ['p(95)<250'],
    http_req_failed: ['rate<0.005'],
  },
};

export default function () {
  const res = http.get(`${__ENV.BASE_URL}/api/accounts`, {
    headers: { Authorization: `Bearer ${__ENV.TOKEN}` },
  });

  check(res, {
    'status 200': (r) => r.status === 200,
  });

  sleep(1);
}
```

### Vari√°veis e Segredos

| Vari√°vel      | Descri√ß√£o                                | Origem                         |
| ------------- | ---------------------------------------- | ------------------------------ |
| `BASE_URL`    | URL p√∫blica do Cloud Run / Load Balancer | `.env` local ou Secret Manager |
| `TOKEN`       | Token gerado via `/api/tokens`           | Criar usu√°rio de teste         |
| `ACCOUNT_ID`  | ID fixo para cen√°rios POST               | Preenchido via script setup    |

No `README` incluir instru√ß√µes para gerar o token automaticamente (ex.: rodar `php artisan user:token` ou chamar endpoint de login via script `setup()` no k6).

### Execu√ß√£o

```bash
cd tests/k6
cp env.example .env          # preencher valores
export $(xargs < .env)
k6 run scenarios/accounts.js
```

Para execu√ß√µes automatizadas (CI/CD ou Cloud Build), usar `k6 run --out cloud` ou integrar com o k6 Cloud se houver licen√ßa. Tamb√©m registrar m√©tricas no Cloud Monitoring via `otel collector` (opcional).

### Coleta e An√°lise

* Armazenar o CSV de resultados (`k6 run --out csv=out/accounts.csv`).  
* Gerar gr√°ficos a partir do CSV (Planilha ou Grafana).  
* Comparar P95/P99 com os SLOs e documentar no cap√≠tulo de resultados.  
* Correlacionar com logs do Cloud Run / Cloud Monitoring (ex.: screenshot de dashboard de CPU/RPS durante o teste).

### Pr√≥ximos Passos Espec√≠ficos

1. Criar diret√≥rio `tests/k6` seguindo a estrutura proposta.  
2. Escrever `README.md` com preparo de ambiente (Credenciais, Base URL, gera√ß√£o de token).  
3. Implementar o primeiro cen√°rio (C1) e executar contra ambiente de staging.  
4. Registrar m√©tricas e ajustar thresholds antes de rodar os demais cen√°rios.  
5. Automatizar a coleta (CSV + dashboards) para uso no TCC.
