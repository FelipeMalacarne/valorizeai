% --- CAPÍTULO 1: INTRODUÇÃO ---
\section{Introdução}
\label{sec:introducao}

\subsection{Contextualização e Motivação}
\label{sec:contextualizacao}

Aplicações digitais modernas, que abrangem desde plataformas de e-commerce e serviços financeiros até mídias sociais e sistemas de colaboração em tempo real,
enfrentam um desafio operacional comum: a gestão de cargas de trabalho (workloads) voláteis e imprevisíveis \cite{google_elasticity_2024}.
Picos de tráfego, eventos contínuos de ingestão de dados e a necessidade de múltiplas integrações com sistemas externos demandam uma infraestrutura que reaja dinamicamente,
muito além da capacidade de provisionamento manual ou pipelines de integração monolíticos e rigidamente acoplados.

A resposta da indústria a esse desafio é a \textit{elasticidade na nuvem} (cloud elasticity),
definida como a capacidade de uma infraestrutura de computação em nuvem alocar e desalocar recursos computacionais de forma automática e autônoma,
com base na flutuação da demanda em tempo real \cite{google_elasticity_2024}.
Diferente da escalabilidade tradicional, que muitas vezes envolve intervenção humana para provisionar novas instâncias,
a elasticidade é projetada para lidar com picos abruptos e vales de tráfego, garantindo tanto o desempenho quanto a eficiência de custos \cite{google_elasticity_2024}.
Os benefícios de negócios são diretos: (1) \textit{Eficiência de Custo}, ao adotar um modelo \textit{pay-as-you-go} que evita o superprovisionamento dispendioso de recursos ociosos;
e (2) \textit{Alta Disponibilidade e Desempenho}, ao assegurar que a aplicação permaneça responsiva e confiável, preservando a experiência do usuário mesmo sob demanda extrema \cite{google_elasticity_2024}.

Contudo, a adoção de arquiteturas que possibilitam essa elasticidade --- notadamente microsserviços, contêineres e paradigmas \textit{serverless} \cite{newrelic_observability_2023} --- introduz um nível exponencial de complexidade.
Sistemas distribuídos são intrinsecamente mais difíceis de depurar e monitorar do que monólitos.
Em resposta, a \textit{observabilidade} (observability) emergiu como uma prioridade estratégica \cite{newrelic_observability_2023}.
A observabilidade transcende o monitoramento tradicional (que rastreia falhas \textit{conhecidas}) ao fornecer \textit{insights} sobre o estado interno do sistema a partir de seus outputs (logs, métricas e traces),
permitindo a depuração de falhas \textit{desconhecidas} \cite{newrelic_observability_2023}.

Elasticidade e observabilidade não são, portanto, características independentes, mas um ciclo de \textit{feedback} simbiótico.
A elasticidade automática gera uma complexidade que só pode ser gerenciada pela observabilidade.
Por sua vez, a observabilidade fornece os dados (na forma de Indicadores de Nível de Serviço, ou SLIs) que alimentam e validam o próprio mecanismo de elasticidade,
garantindo que o escalonamento automático atenda aos objetivos de negócio (SLOs) sem incorrer em custos desnecessários \cite{newrelic_observability_2023}.
A falha de processos manuais é uma consequência direta da alta velocidade desse ciclo, que opera em milissegundos.

O ValorizeAI, objeto deste trabalho, nasce como um estudo de caso completo para investigar essa simbiose.
Trata-se de uma aplicação web modular que centraliza fluxos complexos de ingestão de dados,
processamento síncrono e assíncrono, e entrega de notificações e painéis em tempo real, utilizando uma \textit{stack} de tecnologias modernas.

\subsection{Justificativa e Problema de Pesquisa}
\label{sec:justificativa}

Workloads transacionais que concentram ingestão massiva de dados, gerenciamento de estados compartilhados e interfaces colaborativas --- como os simulados pelo ValorizeAI --- impõem requisitos rigorosos de arquitetura.
Tais sistemas exigem consistência forte nos dados, rastreabilidade completa para fins de auditoria e, fundamentalmente, respostas de baixa latência (respostas instantâneas), mesmo quando o tráfego varia abruptamente.

Para atender a esses requisitos, arquiteturas modernas combinam múltiplos padrões especializados:
\begin{itemize}
    \item \textbf{CDNs e Balanceamento Global:} Para reduzir a latência de entrega de \textit{assets} estáticos, distribuindo o conteúdo para pontos de presença (PoPs) próximos ao usuário \cite{barri_scalability_2025}.
    \item \textbf{Filas Assíncronas (EDA):} Para desacoplar tarefas pesadas (ex: processamento de relatórios, envio de e-mails) da resposta síncrona, garantindo resiliência e escalabilidade através de uma arquitetura orientada a eventos \cite{confluent_eda_2024}.
    \item \textbf{Cache Distribuído (Redis):} Para armazenar dados frequentemente acessados em memória, reduzindo drasticamente a latência de leitura e a carga sobre o banco de dados principal \cite{yadav_redis_leaderboard_2019}.
    \item \textbf{WebSockets (Tempo Real):} Para comunicação bidirecional persistente, essencial para painéis e notificações em tempo real sem a sobrecarga do HTTP \textit{polling} \cite{fernando_websocket_2025}.
\end{itemize}

Embora existam tutoriais e artigos pontuais sobre cada uma dessas tecnologias, a justificativa deste trabalho reside na lacuna da literatura acadêmica e técnica \cite{wjaets_serverless_ml_2022, abad_serverless_gap_2021}.
É raro encontrar material que conecte, de ponta a ponta (end-to-end), a implementação de uma arquitetura híbrida (CaaS + Filas + WebSockets) aos resultados práticos e reprodutíveis de testes de desempenho.
A literatura existente tende a ser fragmentada, focando em comparações de ferramentas de IaC \cite{pessa_iac_2023} ou na validação de microsserviços específicos \cite{hebbar_reactive_2025}, mas raramente no sistema holístico.

A contribuição deste TCC é, portanto, metodológica e empírica.
Ao construir o ValorizeAI e registrar rigorosamente os experimentos de carga e processamento assíncrono,
este trabalho evidencia como as decisões arquiteturais se traduzem em métricas quantificáveis (ex: latência P95, \textit{throughput} de tarefas, taxa de erro).
O problema de pesquisa é: \textit{Como uma arquitetura híbrida e elástica, composta por contêineres gerenciados,
servidor de WebSockets dedicado e filas assíncronas, se comporta sob estresse de carga e qual a metodologia para validar seu desempenho de forma reprodutível contra SLOs pré-definidos?}

Documentar esse caminho, apoiado por Infraestrutura como Código (IaC) para reprodutibilidade e monitoramento de custo,
fornece uma referência concreta para equipes técnicas que precisam justificar e implementar arquiteturas orientadas a eventos com elasticidade horizontal automática.

\subsection{Objetivo Geral}
\label{sec:objetivo_geral}

Demonstrar, por meio de documentação técnica e experimentos de desempenho, que a arquitetura do ValorizeAI --- composta por balanceador com CDN, contêineres escalados horizontalmente, processamento assíncrono em filas, servidor de WebSockets, \textit{buckets} para artefatos e cache em Redis --- sustenta os SLOs definidos para um produto transacional completo, mantendo todo o ciclo (modelagem, desenvolvimento, infraestrutura, observabilidade e testes) versionado no repositório.

\subsection{Objetivos Específicos}
\label{sec:objetivos_especificos}

\begin{enumerate}
    \item \textbf{Mapear a arquitetura end-to-end}, destacando o papel do balanceador/CDN, das instâncias de contêineres, do servidor de WebSockets, das filas assíncronas, dos \textit{buckets} de armazenamento e do Redis para garantir consistência e baixa latência.
    \item \textbf{Documentar o desenvolvimento} do \textit{backend} Laravel, do \textit{frontend} React e dos fluxos síncronos/assíncronos, com foco nos módulos críticos (ingestão de dados, automações, notificações e painéis em tempo real).
    \item \textbf{Planejar e executar os testes de carga} (k6, cenários de leitura e de leitura/escrita) e o teste de processamento assíncrono para validar horizontalmente a arquitetura frente aos SLOs e identificar gargalos.
    \item \textbf{Interpretar os resultados e propor otimizações}, relacionando desempenho, elasticidade e custo (ex.: ajustes de limites de instância, estratégias de cache) e apontando como essas evidências fundamentam decisões para \textit{workloads} transacionais de alta criticidade.
\end{enumerate}

\subsection{Estrutura do Trabalho}
\label{sec:estrutura}

Este trabalho está organizado da seguinte forma: O Capítulo \ref{sec:relacionados} apresenta uma revisão da literatura sobre paradigmas de execução em nuvem, padrões arquiteturais e metodologias de validação, identificando a lacuna que este TCC se propõe a preencher. O Capítulo \ref{sec:fundamentacao} define os conceitos teóricos e técnicos canônicos que fundamentam o design do sistema e a metodologia de testes. O Capítulo 4 detalha a metodologia empregada, incluindo os SLOs definidos e a configuração dos testes. O Capítulo 5 descreve a implementação da arquitetura ValorizeAI. O Capítulo 6 apresenta e discute os resultados dos experimentos de desempenho. Finalmente, o Capítulo 7 conclui o trabalho e sugere direções para pesquisas futuras.

\newpage
