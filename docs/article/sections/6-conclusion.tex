\section{Conclusão}

\subsection{Principais Contribuições}

O ValorizeAI demonstrou que é possível documentar e validar, de ponta a ponta, uma arquitetura orientada a eventos construída exclusivamente com serviços gerenciados. O trabalho conecta decisões de design (Cloud Run, Redis, Cloud SQL, Cloud Tasks, Reverb) ao domínio transacional modelado no banco relacional, oferecendo um roteiro explícito para equipes que precisam de elasticidade sem perder consistência forte. A metodologia experimental, baseada em SRE, complementa essa documentação ao detalhar como planejar SLOs, materializar infraestrutura como código e acionar testes repetíveis, fortalecendo a reprodutibilidade típica de uma pesquisa aplicada.

\subsection{Resultados Alcançados}

Os cenários de carga comprovaram a eficácia das otimizações de leitura: com 1.000 usuários virtuais, o sistema manteve latência P95 em 158~ms e zero erros, satisfazendo os SLOs estabelecidos. O cenário misto, por sua vez, revelou o limiar atual do sistema; a latência P95 de 4{,}03~s e o throughput de 101 req/s evidenciam que operações de escrita concorrentes pressionam o banco relacional e o pipeline de invalidação de cache, sobretudo sob a cota de 10~vCPU disponível. No plano assíncrono, a drenagem de 51{,}58~mil tarefas em 10~min confirmou que Cloud Tasks e workers em Cloud Run sustentam bursts significativos sem intervenção humana, atendendo aos requisitos de elasticidade e rastreabilidade.

\subsection{Limitações}

Dois fatores limitam os resultados. Primeiro, o ambiente operou com as cotas padrão de uma conta recém-provisionada (10 instâncias de 1~vCPU), o que restringe a observação de comportamentos em estágios superiores de escala. Segundo, o banco de dados permaneceu concentrado em uma única instância Cloud SQL regional; embora consistente, essa configuração impõe contenções em workloads que concentram escritas nas mesmas contas ou categorias. Além disso, os gráficos e séries temporais ainda não estão incorporados ao artigo; os espaços reservados indicam onde a visualização das métricas será anexada.

\subsection{Trabalhos Futuros}

As próximas etapas incluem ampliar a quota de Cloud Run para repetir os testes em 20 ou 40~vCPU, avaliar estratégias de particionamento lógico ou réplicas especializadas para aliviar locks de escrita e introduzir mecanismos de autofalover multi-região para o Cloud SQL e o Redis. Também se pretende complementar o pipeline assíncrono com um orquestrador baseado em eventos (ex.: Workflows) para medir a resiliência a falhas parciais, e estender o uso de embeddings e automações de categorização para outras áreas (como detecção de anomalias). Por fim, a instrumentação gráfica citada nos Resultados deve ser adicionada ao texto final, fechando o pacote de evidências do TCC.
