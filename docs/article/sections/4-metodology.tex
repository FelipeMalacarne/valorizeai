\section{Metodologia}
\label{sec:metodologia}

O estudo foi conduzido de ponta a ponta, do planejamento dos objetivos de nível de serviço (SLOs) à coleta e interpretação dos experimentos. O enfoque é aplicado e experimental: toda a instrumentação foi construída diretamente no repositório ValorizeAI, o que permite a reprodução dos resultados.

\subsection{Tipo de Pesquisa e Estratégia Geral}

O trabalho caracteriza-se como uma \textbf{pesquisa aplicada} conduzida como \textbf{estudo de caso} de um sistema real em produção. A estratégia seguiu quatro fases iterativas. No \textbf{planejamento}, foram definidos os SLOs (latência P95 de 250~ms, erro $<$0{,}5\%, disponibilidade $\geq$99{,}5\%), mapeadas as cotas vigentes do Cloud Run (10 instâncias de 1~vCPU / 1~GiB, totalizando 10 vCPU) e estimado como essa limitação poderia afetar o throughput — nos ensaios preliminares o workload saturou próximo de 900 RPS, valor usado apenas como referência empírica. Em seguida veio a \textbf{preparação do ambiente}: módulos Terraform provisionaram rede, bancos e serviços gerenciados; Docker Compose reproduziu localmente PostgreSQL, Redis e a stack de observabilidade; o Makefile encapsulou tarefas de lint, testes e execução dos cenários. Na etapa de \textbf{execução controlada}, os cenários k6 de leitura e leitura/escrita foram disparados contra a API em Cloud Run enquanto o pipeline assíncrono recebia um lote adicional de tarefas no Cloud Tasks, exercitando os workers HTTP. Por fim, na \textbf{coleta e análise}, as métricas agregadas (latência, throughput, taxa de erro) foram extraídas dos CSVs e painéis do Cloud Monitoring, e as observações qualitativas sobre o teste de filas foram registradas juntamente com o tempo total de drenagem, subsidiando os capítulos de implementação e resultados.

\subsection{Arquitetura do Ambiente Experimental}

A Figura \ref{fig:arquitetura} sintetiza os componentes usados nos experimentos. O tráfego HTTP/HTTPS entra por um \textbf{Cloud Load Balancer} com \textbf{Cloud CDN}, que reduz a latência de \textit{assets} estáticos e protege o backend com inspeção WAF. Esse tráfego é encaminhado para dois serviços Cloud Run:
\begin{itemize}
    \item \textbf{API Laravel}: processa requisições REST, expõe endpoints usados pelos testes k6 e orquestra o pipeline assíncrono.
    \item \textbf{Laravel Reverb}: mantém conexões WebSocket persistentes para eventos em tempo real; é tratado como serviço independente para permitir escalonamento específico.
\end{itemize}

Ambos os serviços acessam o \textbf{Memorystore for Redis}, usado simultaneamente como cache de leitura (padrão \textit{cache-aside}) e como \textit{backplane} Pub/Sub do Reverb. O armazenamento transacional permanece no \textbf{Cloud SQL for PostgreSQL}, que atende às operações de leitura e escrita executadas durante os testes. Para workloads assíncronos, a API publica tarefas em \textbf{Cloud Tasks}, que aciona workers HTTP também hospedados no Cloud Run. Artefatos grandes (extratos e relatórios) são persistidos no \textbf{Cloud Storage}, mas não fizeram parte dos testes de carga.

\begin{figure}[ht]
    \centering
    \resizebox{\linewidth}{!}{%
    \begin{tikzpicture}[node distance=1.5cm, every node/.style={font=\footnotesize, align=center}]
        \node (cdn) [draw, rounded corners, fill=gray!15, minimum width=5cm, minimum height=0.9cm] {Cloud Load Balancer + Cloud CDN};
        \node (api) [draw, rounded corners, fill=blue!10, minimum width=3cm, minimum height=0.9cm, below left=1.1cm and 2.0cm of cdn] {Cloud Run\\API};
        \node (reverb) [draw, rounded corners, fill=blue!10, minimum width=3cm, minimum height=0.9cm, below=1.1cm of cdn] {Cloud Run\\Reverb};
        \node (workers) [draw, rounded corners, fill=blue!10, minimum width=3cm, minimum height=0.9cm, below right=1.1cm and 2.0cm of cdn] {Cloud Run\\Workers};
        \node (shared) [draw, rounded corners, fill=orange!15, minimum width=6cm, minimum height=1.2cm, below=1.3cm of reverb] {Cloud SQL + Memorystore (Redis) + Cloud Storage};
        \node (tasks) [draw, rounded corners, fill=green!10, minimum width=5cm, minimum height=0.9cm, below=1.0cm of shared] {Cloud Tasks};

        \draw[->, thick] (cdn) -- (api);
        \draw[->, thick] (cdn) -- (reverb);
        \draw[->, thick] (cdn) -- (workers);
        \draw[->, thick] (api) -- (shared);
        \draw[->, thick] (reverb) -- (shared);
        \draw[->, thick] (workers) -- (shared);
        \draw[->, thick] (api) |- (tasks);
        \draw[->, thick] (tasks) -| (workers);
    \end{tikzpicture}}
    \caption{Arquitetura utilizada nos experimentos.}
    \label{fig:arquitetura}
\end{figure}

\subsection{Ferramentas e Processo de Preparação}

Do ponto de vista de engenharia, três pilares garantiram a reprodutibilidade:
\textbf{(i)} \emph{Infraestrutura como Código}: os módulos Terraform descrevem VPC, balanceadores, Cloud Run, Cloud SQL, Redis e Cloud Tasks. Cada mudança passa por \textit{plan/apply} versionado, evitando deriva de ambiente.
\textbf{(ii) Ambientes determinísticos}: o Makefile e os manifestos Docker recompõem o stack local (PostgreSQL, Redis, Loki/Tempo e PHP 8.4) idêntico ao ambiente de teste antes de qualquer execução k6.
\textbf{(iii) Observabilidade}: OpenTelemetry + Cloud Monitoring coletam métricas de latência, uso CPU/memória e backlog de filas, permitindo correlacionar cada rodada com os SLOs definidos.

\subsection{Planejamento dos SLOs e Desenho dos Cenários}

Com base nas premissas de negócio e na literatura de SRE \cite{mccoy_slo_2020,google_sre_book_main}, o sistema foi avaliado contra três metas: latência P95 $\leq 250$~ms, taxa de erro $<$ 0{,}5\% e disponibilidade mensal $\geq 99{,}5\%$. A cota vigente do Cloud Run (10 instâncias de 1~vCPU/1~GiB) limita o total de CPU disponível; no nosso cenário isso significou que os testes deveriam aumentar a carga até consumir essas 10 vCPU (o que, empiricamente, ocorreu perto de 900 RPS), documentando o comportamento imediatamente antes do esgotamento.

Dois cenários foram modelados:
\begin{enumerate}
    \item \textbf{Leitura intensiva}: 1{.}000 usuários virtuais consultando listas de transações por 17 minutos em seis estágios, exercitando cache Redis + réplica de leitura do PostgreSQL.
    \item \textbf{Mistura leitura/escrita}: 650 usuários virtuais alternando consultas e criação de transações durante 21 minutos, forçando locks no banco e pressionando o pipeline de escrita.
\end{enumerate}
Além desses ensaios HTTP, foi planejado um \textbf{teste de filas} no qual um volume elevado de tarefas artificiais percorre o fluxo Cloud Tasks → workers HTTP, permitindo observar o tempo de drenagem e a elasticidade dos consumidores assíncronos.

\subsection{Execução dos Experimentos}

Cada rodada segue os passos:
\begin{enumerate}
    \item \textbf{Preparação dos dados}: seeds e factories povoam o PostgreSQL com contas, transações e orçamentos realistas; a instância Redis é pre-aquecida com métricas e dashboards frequentes.
    \item \textbf{Disparo do cenário}: os perfis do k6 focados em leitura e no mix leitura/escrita são executados via Makefile, apontando para o domínio público do Cloud Load Balancer; estágios, VUs e SLIs monitorados seguem o planejamento experimental.
    \item \textbf{Registro automático}: os resultados agregados são gravados em CSVs (latência, taxa de erro, uso de VUs) e correlacionados com as métricas de infraestrutura capturadas pelo Cloud Monitoring.
    \item \textbf{Teste de filas}: um script HTTP produz um lote adicional de tarefas e a drenagem é acompanhada por meio das métricas do Cloud Tasks e dos logs dos workers.
\end{enumerate}

\subsection{Coleta e Integração das Evidências}

As evidências produzidas sustentam as análises de arquitetura, implementação e resultados:
\begin{itemize}
    \item \textbf{Planilhas de latência e throughput}: derivadas dos CSVs exportados pelo k6, utilizadas posteriormente para comparar as métricas observadas com os SLOs.
    \item \textbf{Series temporais de infraestrutura}: capturas dos dashboards do Cloud Monitoring registram uso de CPU das instâncias Cloud Run, saturação do Redis e backlog do Cloud Tasks durante cada rodada.
    \item \textbf{Relatos de execução}: cada rodada é registrada em um diário experimental com horários, parâmetros e observações qualitativas sobre o comportamento do sistema.
\end{itemize}

Essa metodologia garante rastreabilidade completa entre arquitetura, implementação e resultados, pois cada passo experimental está ancorado em artefatos versionados do projeto.
