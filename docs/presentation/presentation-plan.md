Beleza, vamos focar em te **preparar pra banca**, nÃ£o no PowerPoint em si ğŸ˜„

Vou te passar:

* **Estrutura sugerida de slides** (vocÃª monta no modelo da instituiÃ§Ã£o)
* **O que escrever em cada slide (bullets)**
* **Um roteiro de fala em voz alta pra cada slide**
* Com ideia de tempo pra fechar em ~15 minutos

Tudo baseado no teu artigo do ValorizeAI .

---

## VisÃ£o geral da apresentaÃ§Ã£o (15 min / 10â€“11 slides)

SugestÃ£o de estrutura (que encaixa no modelo: IntroduÃ§Ã£o / Metodologia / Resultados / ReferÃªncias):

1. TÃ­tulo
2. SumÃ¡rio
3. Contexto & MotivaÃ§Ã£o
4. Problema, lacuna e pergunta de pesquisa
5. Objetivo geral e especÃ­ficos
6. Arquitetura do ValorizeAI
7. Metodologia experimental (SLOs, k6, IaC)
8. Resultados â€“ cenÃ¡rio de leitura
9. Resultados â€“ cenÃ¡rio misto + assÃ­ncrono
10. ConclusÃµes, limitaÃ§Ãµes e trabalhos futuros
11. Agradecimento / Perguntas (opcional, se couber)

---

## SLIDE 1 â€“ TÃ­tulo (â‰ˆ 30â€“40 s)

**No slide (bem direto):**

> ValorizeAI: DocumentaÃ§Ã£o e ValidaÃ§Ã£o de uma Arquitetura Serverless Elasticamente Gerenciada
> Autor: Felipe Tomkiel Malacarne
> Orientador: Prof. Me. Marcos AndrÃ© Lucas
> Curso de CiÃªncia da ComputaÃ§Ã£o â€“ URI Erechim â€“ 2025

**Fala sugerida:**

> â€œBoa tarde a todos. Meu nome Ã© Felipe Malacarne e vou apresentar meu Trabalho de ConclusÃ£o de Curso, intitulado *â€˜ValorizeAI: DocumentaÃ§Ã£o e ValidaÃ§Ã£o de uma Arquitetura Serverless Elasticamente Gerenciadaâ€™*.
> Esse trabalho foi desenvolvido sob orientaÃ§Ã£o do professor Marcos AndrÃ© Lucas, no curso de CiÃªncia da ComputaÃ§Ã£o da URI Erechim.â€

Se quiser, emenda:

> â€œA ideia central Ã© avaliar, na prÃ¡tica, como uma arquitetura moderna baseada em serviÃ§os gerenciados em nuvem se comporta sob carga intensa em um cenÃ¡rio financeiro real.â€

---

## SLIDE 2 â€“ SumÃ¡rio (â‰ˆ 40â€“50 s)

**No slide:**

* IntroduÃ§Ã£o
* Metodologia
* Resultados
* ConclusÃµes e Trabalhos Futuros

**Fala sugerida:**

> â€œA apresentaÃ§Ã£o estÃ¡ organizada em quatro partes.
> Primeiro, faÃ§o uma breve **introduÃ§Ã£o** ao problema e Ã  motivaÃ§Ã£o do trabalho.
> Depois, explico a **metodologia**, incluindo a arquitetura do sistema e como os testes foram conduzidos.
> Em seguida, apresento os **principais resultados** obtidos.
> E, por fim, trago as **conclusÃµes**, limitaÃ§Ãµes e propostas de trabalhos futuros.â€

---

## SLIDE 3 â€“ Contexto & MotivaÃ§Ã£o (â‰ˆ 1,5 min) â€“ *IntroduÃ§Ã£o*

**No slide (poucos bullets):**

* Plataformas financeiras: trÃ¡fego variÃ¡vel, forte consistÃªncia, baixa latÃªncia
* Elasticidade em nuvem (Cloud Run, serviÃ§os gerenciados)
* Complexidade â†’ necessidade de observabilidade e validaÃ§Ã£o integrada 

**Fala sugerida:**

> â€œO contexto deste trabalho sÃ£o **plataformas financeiras modernas**, que lidam com picos de transaÃ§Ãµes, muita leitura e escrita, e ao mesmo tempo precisam manter **consistÃªncia forte, baixa latÃªncia e alta disponibilidade**.
> A resposta comum a isso Ã© usar a **elasticidade da nuvem** â€“ serviÃ§os como Cloud Run, Cloud SQL, Redis gerenciado, filas, etc., que escalam automaticamente conforme a carga.
> O problema Ã© que, conforme a arquitetura vai ficando mais distribuÃ­da e elÃ¡stica, cresce tambÃ©m a **complexidade de entender e observar o sistema**. Logs, mÃ©tricas e traces passam a ser fundamentais, e surge a necessidade de **validar na prÃ¡tica** se aquela arquitetura realmente aguenta a carga que se espera dela.â€

Se quiser reforÃ§ar:

> â€œO ValorizeAI entra como um caso real para estudar essa relaÃ§Ã£o entre elasticidade e observabilidade em um cenÃ¡rio financeiro.â€

---

## SLIDE 4 â€“ Problema, Lacuna e Pergunta de Pesquisa (â‰ˆ 1,5 min) â€“ *IntroduÃ§Ã£o*

**No slide:**

* Literatura trata **componentes isolados** (FaaS vs CaaS, filas, IaC, etc.)
* Poucos estudos **end-to-end** de arquiteturas hÃ­bridas (CaaS + filas + WebSockets) 
* **Pergunta:** como essa arquitetura se comporta sob carga intensa?

**Fala sugerida:**

> â€œQuando a gente olha para a literatura, existem vÃ¡rios trabalhos bons, mas quase sempre olhando **um pedaÃ§o** do problema:
> â€“ comparaÃ§Ã£o entre FaaS e CaaS;
> â€“ estudos de diferentes filas, como RabbitMQ, Kafka, Pulsar;
> â€“ comparaÃ§Ãµes entre ferramentas de Infraestrutura como CÃ³digo;
> â€“ ou estudos de desempenho focados em uma Ãºnica API.
>
> O que praticamente **nÃ£o aparece** sÃ£o validaÃ§Ãµes **integradas**, de ponta a ponta, em um sistema real que combine tudo isso: containers gerenciados, filas assÃ­ncronas, WebSockets, cache, banco relacional e SRE.
>
> EntÃ£o a **pergunta central** do trabalho Ã©:
> *â€˜Como uma arquitetura hÃ­brida e elÃ¡stica, composta por Cloud Run, Redis, Cloud SQL, Cloud Tasks e WebSockets dedicados, se comporta sob condiÃ§Ãµes intensas de carga, e como esse comportamento pode ser validado de forma reprodutÃ­vel?â€™*â€

---

## SLIDE 5 â€“ Objetivo Geral e EspecÃ­ficos (â‰ˆ 1 min) â€“ *IntroduÃ§Ã£o*

**No slide:**

**Objetivo geral**

* Documentar e validar, por meio de experimentos de desempenho, a arquitetura do ValorizeAI.

**Objetivos especÃ­ficos** (em bullets):

* Mapear a arquitetura end-to-end
* Documentar mÃ³dulos crÃ­ticos (ingestÃ£o, automaÃ§Ãµes, notificaÃ§Ãµes, dashboards)
* Planejar e executar testes de carga com k6
* Validar SLOs de latÃªncia, erro e disponibilidade
* Propor otimizaÃ§Ãµes de escalabilidade e custo 

**Fala sugerida:**

> â€œO **objetivo geral** Ã© demonstrar, de forma prÃ¡tica, que a arquitetura do ValorizeAI consegue sustentar metas de desempenho e confiabilidade tÃ­picas de um produto financeiro real.
>
> Para isso, eu:
> â€“ mapeei a arquitetura completa;
> â€“ documentei os mÃ³dulos mais crÃ­ticos para o fluxo transacional;
> â€“ defini SLOs claros de latÃªncia, erro e disponibilidade;
> â€“ executei cenÃ¡rios de carga reprodutÃ­veis com k6;
> â€“ e, a partir dos resultados, propus ajustes e otimizaÃ§Ãµes.â€

---

## SLIDE 6 â€“ Arquitetura do ValorizeAI (â‰ˆ 2 min) â€“ *ConteÃºdo / Metodologia*

Aqui Ã© um Ã³timo lugar pra colocar a **Figura 1** (arquitetura) no slide.

**No slide (texto curto ao lado ou abaixo da figura):**

* Cloud Load Balancer + Cloud CDN
* 3 serviÃ§os Cloud Run: API, Reverb (WebSocket), Workers
* Cloud SQL (PostgreSQL), Redis (Memorystore), Cloud Tasks 

**Fala sugerida (explicando a figura):**

> â€œAqui estÃ¡ a **visÃ£o geral da arquitetura** utilizada nos experimentos.
> O trÃ¡fego chega pelo **Load Balancer** com **CDN**, que cuida da distribuiÃ§Ã£o e de conteÃºdo estÃ¡tico.
> A aplicaÃ§Ã£o em si Ã© dividida em trÃªs serviÃ§os no **Cloud Run**:
>
> * A **API Laravel**, que atende as requisiÃ§Ãµes HTTP;
> * O **servidor de WebSockets** com Laravel Reverb, responsÃ¡vel pela comunicaÃ§Ã£o em tempo real;
> * E os **workers**, que processam tarefas assÃ­ncronas disparadas pelo Cloud Tasks.
>
> O **Cloud SQL** mantÃ©m o banco transacional em PostgreSQL;
> o **Redis** funciona tanto como **cache** de leitura quanto como **backplane Pub/Sub** para o Reverb;
> e o **Cloud Tasks** gerencia o pipeline assÃ­ncrono, permitindo que o sistema absorva rajadas de tarefas sem travar a API.â€

Se quiser, arremata:

> â€œTudo isso Ã© provisionado como cÃ³digo, usando Terraform, o que permite recriar o ambiente de forma determinÃ­stica.â€

---

## SLIDE 7 â€“ Metodologia Experimental (â‰ˆ 2 min) â€“ *Metodologia*

**No slide:**

* Metodologia aplicada, estudo de caso real
* SLOs:

  * P95 â‰¤ 300 ms
  * Erro < 0,5%
  * Disponibilidade â‰¥ 99,5%
* Ferramentas: Terraform, Docker, Makefile, k6, Cloud Monitoring
* 3 cenÃ¡rios de teste:

  * Leitura intensiva
  * Leitura/Escrita
  * Pipeline assÃ­ncrono (Cloud Tasks) 

**Fala sugerida:**

> â€œA metodologia Ã© um **estudo de caso aplicado** sobre uma aplicaÃ§Ã£o real.
> Eu sigo princÃ­pios de **SRE**, comeÃ§ando pela definiÃ§Ã£o de **SLOs**:
>
> * latÃªncia P95 menor ou igual a 300 ms;
> * taxa de erro menor que 0,5%;
> * e disponibilidade maior ou igual a 99,5%.
>
> Toda a infraestrutura Ã© provisionada com **Terraform**, os ambientes sÃ£o reproduzidos com Docker e Makefile, e os testes de carga sÃ£o executados com o **k6**, contra o domÃ­nio real da API.
>
> Foram definidos trÃªs cenÃ¡rios:
>
> * um cenÃ¡rio de **leitura intensiva**, focado em GET /api/transactions;
> * um cenÃ¡rio **misto**, combinando leitura e escrita de transaÃ§Ãµes;
> * e um teste do **pipeline assÃ­ncrono**, publicando mais de 50 mil tarefas no Cloud Tasks e monitorando a drenagem.â€

---

## SLIDE 8 â€“ Resultados: CenÃ¡rio de Leitura (â‰ˆ 2 min) â€“ *Resultados*

Se tiver como, coloca aqui a figura das latÃªncias P50/P95/P99 do cenÃ¡rio de leitura (Figura 6).

**No slide (texto curto + grÃ¡fico):**

* 1.000 usuÃ¡rios virtuais (VUs)
* ~470 req/s (pico ~970 req/s)
* P95 = 158 ms (bem abaixo do SLO)
* 0% de erros 

**Fala sugerida:**

> â€œNo cenÃ¡rio de **leitura intensiva**, eu simulei atÃ© **1.000 usuÃ¡rios virtuais** acessando o endpoint de listagem de transaÃ§Ãµes, durante cerca de 17 minutos.
> O sistema sustentou em mÃ©dia **470 requisiÃ§Ãµes por segundo**, chegando a picos prÃ³ximos de **970 req/s**.
>
> A latÃªncia **P95 ficou em 158 ms**, ou seja, bem abaixo do limite de 300 ms definido no SLO, e **nenhuma requisiÃ§Ã£o falhou**.
>
> Esse resultado mostra que o caminho de leitura â€” combinando CDN, API em Cloud Run, **Redis como cache** e consultas eficientes no PostgreSQL â€” Ã© bastante robusto e escala bem sob carga.â€

---

## SLIDE 9 â€“ Resultados: CenÃ¡rio Misto + AssÃ­ncrono (â‰ˆ 3 min) â€“ *Resultados*

Aqui vocÃª pode dividir em dois blocos no mesmo slide (ou dois slides, se estiver confortÃ¡vel).

**No slide (parte 1 â€“ cenÃ¡rio misto):**

* 650 VUs (65% leitura, 35% escrita)
* ~226 req/s
* P95 = 658 ms; p99 = 2,67 s
* SaturaÃ§Ã£o em 10 instÃ¢ncias de Cloud Run (gargalo na camada HTTP) 

**Fala sugerida (misto):**

> â€œNo **cenÃ¡rio misto**, cada usuÃ¡rio virtual alternava entre leituras e escritas, aproximando-se do padrÃ£o observado no uso real.
> Com **650 VUs**, o sistema manteve cerca de **226 requisiÃ§Ãµes por segundo**.
>
> Aqui, o comportamento muda: o P95 da latÃªncia sobe para **658 ms** e o p99 chega a **2,67 segundos**, violando o SLO de 300 ms.
> A anÃ¡lise das mÃ©tricas mostra que o gargalo nÃ£o foi o banco de dados, e sim a **camada HTTP no Cloud Run**, que chegou ao limite de **10 instÃ¢ncias** configuradas.
>
> Isso faz sentido, porque o caminho de escrita Ã© mais pesado: envolve validaÃ§Ãµes, transaÃ§Ãµes ACID e invalidaÃ§Ã£o de cache.â€

**No slide (parte 2 â€“ pipeline assÃ­ncrono):**

* 51.580 tarefas no Cloud Tasks
* â‰ˆ 10 minutos â†’ â‰ˆ 86 tarefas/s
* Escalonamento automÃ¡tico de workers
* Sem perdas ou duplicaÃ§Ãµes 

**Fala sugerida (assÃ­ncrono):**

> â€œJÃ¡ no **pipeline assÃ­ncrono**, foram publicadas **51.580 tarefas** em lote.
> Em aproximadamente **10 minutos**, todas foram processadas, o que dÃ¡ em torno de **86 tarefas por segundo em mÃ©dia**.
>
> O Cloud Run escalou automaticamente o nÃºmero de **workers** enquanto havia backlog, reduzindo depois que a fila esvaziou.
> NÃ£o houve **perda** nem **duplicaÃ§Ã£o** de tarefas, o que mostra um comportamento elÃ¡stico e confiÃ¡vel para workloads assÃ­ncronos.â€

---

## SLIDE 10 â€“ ConclusÃµes, LimitaÃ§Ãµes e Trabalhos Futuros (â‰ˆ 2â€“3 min) â€“ *Resultados / ConclusÃµes*

VocÃª pode usar trÃªs blocos: **ConclusÃµes**, **LimitaÃ§Ãµes**, **Trabalhos futuros**.

**No slide â€“ ConclusÃµes:**

* Arquitetura atende bem workloads intensivos em leitura
* Escrita concorrente limitada pela cota de instÃ¢ncias HTTP
* Pipeline assÃ­ncrono (Cloud Tasks + workers) Ã© elÃ¡stico e confiÃ¡vel 

**Fala sugerida (conclusÃµes):**

> â€œComo conclusÃ£o, o trabalho mostrou que:
>
> * a arquitetura do ValorizeAI **suporta muito bem workloads de leitura**, mesmo em cenÃ¡rios com mil usuÃ¡rios simultÃ¢neos;
> * o ponto de atenÃ§Ã£o estÃ¡ nos **caminhos de escrita**, onde o limite de instÃ¢ncias e o custo computacional por requisiÃ§Ã£o acabam degradando a latÃªncia;
> * e o pipeline assÃ­ncrono, baseado em Cloud Tasks e workers em Cloud Run, se mostrou **bastante eficiente** para processar grandes volumes sem intervenÃ§Ã£o manual.â€

**No slide â€“ LimitaÃ§Ãµes:**

* Cota de 10 instÃ¢ncias (1 vCPU) no Cloud Run
* Banco em uma Ãºnica instÃ¢ncia regional 

**Fala sugerida (limitaÃ§Ãµes):**

> â€œDuas limitaÃ§Ãµes principais influenciam os resultados:
>
> * a infraestrutura foi testada com as **cotas padrÃ£o** de um projeto recÃ©m-provisionado, com apenas 10 instÃ¢ncias de 1 vCPU para a API;
> * o banco permaneceu em uma **Ãºnica instÃ¢ncia** regional do Cloud SQL, o que, em cenÃ¡rios ainda maiores, pode se tornar um gargalo.â€

**No slide â€“ Trabalhos futuros:**

* Repetir testes com mais vCPUs/instÃ¢ncias
* RÃ©plicas de leitura e particionamento
* EvoluÃ§Ã£o de embeddings e automaÃ§Ãµes (detecÃ§Ã£o de anomalias, recomendaÃ§Ãµes) 

**Fala sugerida (futuro):**

> â€œComo prÃ³ximos passos, Ã© interessante:
>
> * repetir os testes com **limites maiores de instÃ¢ncias e CPU**, para ver onde surgem novos gargalos;
> * estudar o uso de **rÃ©plicas de leitura** e talvez **particionamento de dados** para aliviar as rotas mais crÃ­ticas;
> * e evoluir o uso de **embeddings** e automaÃ§Ãµes do ValorizeAI para cenÃ¡rios como detecÃ§Ã£o de anomalias e recomendaÃ§Ãµes financeiras.â€

---

## SLIDE 11 â€“ Encerramento / Perguntas (â‰ˆ 30â€“40 s)

**No slide (simples):**

> Obrigado!
> Perguntas?

**Fala sugerida:**

> â€œCom isso, encerro a apresentaÃ§Ã£o do meu trabalho.
> AgradeÃ§o a atenÃ§Ã£o de vocÃªs e fico Ã  disposiÃ§Ã£o para dÃºvidas e comentÃ¡rios.â€

---

## Dicas rÃ¡pidas de entrega (pra treinar):

1. **NÃ£o leia os slides.** Use os bullets como gatilho e conte com suas palavras.
2. **Treina com cronÃ´metro**:

   * 2â€“3 min para IntroduÃ§Ã£o (slides 3,4,5)
   * 4â€“5 min para Arquitetura + Metodologia (6,7)
   * 5â€“6 min para Resultados (8,9)
   * 2â€“3 min para ConclusÃµes (10,11)
3. Deixa sempre **1 exemplo concreto** na ponta da lÃ­ngua, tipo:

   > â€œSe amanhÃ£ dobrar o nÃºmero de usuÃ¡rios consultando extratos, o cenÃ¡rio de leitura mostra que a arquitetura aguenta bem esse tipo de carga.â€

---

Se vocÃª quiser, no prÃ³ximo passo eu posso:

* **Transformar esse roteiro em â€œfalas em primeira pessoaâ€ ainda mais fluÃ­das**, como se fosse um texto contÃ­nuo pra decorar; ou
* Montar uma **versÃ£o ultra-resumida** sÃ³ com frases-chave pra vocÃª usar no dia da apresentaÃ§Ã£o.
