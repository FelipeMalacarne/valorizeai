


Boa tarde a todos. Meu nome √© Felipe Malacarne e vou apresentar meu Trabalho de Conclus√£o de Curso, intitulado *ValorizeAI: Documenta√ß√£o e Valida√ß√£o de uma Arquitetura Serverless Elasticamente Gerenciada*.
Esse trabalho foi desenvolvido sob orienta√ß√£o do professor Marcos Andr√© Lucas, no curso de Ci√™ncia da Computa√ß√£o da URI Erechim

A ideia central √© avaliar, na pr√°tica, como uma arquitetura moderna baseada em servi√ßos gerenciados em nuvem ‚Äî que escalam sob demanda e cobram apenas pelo uso ‚Äî se comporta sob carga intensa em uma aplica√ß√£o web real, com cargas vari√°veis.

**SLIDE 2 ‚Äî Sum√°rio**

A apresenta√ß√£o est√° organizada em quatro partes:
primeiro, a **introdu√ß√£o**, onde apresento o problema e a motiva√ß√£o;
depois a **metodologia**, incluindo a arquitetura do sistema e como os testes foram conduzidos;
na sequ√™ncia, os **resultados** dos cen√°rios de carga;
e por fim, as **conclus√µes** e os trabalhos futuros.

**SLIDE 3 ‚Äî Contexto e Motiva√ß√£o**

O contexto deste trabalho s√£o **aplica√ß√µes web modernas**, como plataformas colaborativas, e-commerces, APIs e sistemas financeiros, que convivem com **tr√°fego vari√°vel**, exigem **baixa lat√™ncia**, **forte consist√™ncia** e alta disponibilidade.
Para lidar com esse cen√°rio, cresce o uso de arquiteturas **el√°sticas** . Elas escalam automaticamente quando h√° demanda, e reduzem ‚Äî at√© mesmo a zero ‚Äî quando o tr√°fego desaparece, evitando custo ocioso.

Por outro lado, conforme esses sistemas ficam mais distribu√≠dos, aumenta a necessidade de **observabilidade**: logs, m√©tricas, traces e testes reprodut√≠veis.
A quest√£o central passa a ser: *essa arquitetura realmente entrega o desempenho esperado quando √© pressionada por carga real?*

O ValorizeAI entra como um caso real para estudar essa rela√ß√£o entre elasticidade e observabilidade em cen√°rios de cargas vari√°veis em aplica√ß√µes web em geral.

---

**SLIDE 4 ‚Äî Problema, Lacuna e Pergunta de Pesquisa**

Quando a gente olha para a literatura, existem v√°rios trabalhos bons, mas quase sempre olhando **um peda√ßo** do problema:
‚Äì compara√ß√£o entre FaaS e CaaS;
‚Äì estudos de diferentes filas, como RabbitMQ e Kafka;
‚Äì compara√ß√µes entre ferramentas de Infraestrutura como C√≥digo;
‚Äì ou estudos de desempenho focados em uma √∫nica API.

O que praticamente **n√£o aparece** s√£o valida√ß√µes **integradas**, de ponta a ponta, em um sistema real que combine tudo isso: containers gerenciados, filas ass√≠ncronas, WebSockets, cache, banco relacional e SRE.

Ent√£o a **pergunta central** do trabalho √©:
*‚ÄòComo uma arquitetura h√≠brida e el√°stica, composta por Cloud Run, Redis, PostgreSQL, Filas e WebSockets dedicados, se comporta sob condi√ß√µes intensas de carga, e como esse comportamento pode ser validado de forma reprodut√≠vel?‚Äô*‚Äù

---

**SLIDE 5 ‚Äî Objetivo Geral e Espec√≠ficos**

O objetivo geral √© **documentar e validar**, por meio de experimentos de desempenho, a arquitetura do ValorizeAI, representando um tipo de aplica√ß√£o web moderna sujeita a carga vari√°vel.

Para isso,
eu mapeei a arquitetura completa,
documentei os m√≥dulos cr√≠ticos,
defini SLOs claros de lat√™ncia, erro e disponibilidade,
executei cen√°rios de carga com k6,
e por fim, propus otimiza√ß√µes de escalabilidade e custo.

---

**SLIDE 6 ‚Äî Arquitetura do Sistema**

Esta √© a vis√£o geral da arquitetura.
O tr√°fego entra pelo Load Balancer, que distribui requisi√ß√µes para seu determinado servi√ßo.
Com a CDN que serve o conteudo est√°tico da aplica√ß√£o, como os assests do frontend, de maneira eficiente e distribuida. 
A aplica√ß√£o possui tr√™s servi√ßos principais no Cloud Run:

* a **API Laravel**, stateless, que atende requisi√ß√µes HTTP;
* o **servidor de WebSockets**, usando Laravel Reverb;
* e os **workers**, respons√°veis por tarefas ass√≠ncronas.

O banco transacional √© mantido no **Cloud SQL PostgreSQL**.
O **Redis** atua tanto como cache quanto como backplane para o Sevidor de websocket.
E o **Cloud Tasks** gerencia o pipeline ass√≠ncrono.

Um ponto importante aqui √© a **elasticidade**: todos os servi√ßos sobem e descem automaticamente conforme a carga ‚Äî inclusive podendo chegar a zero ‚Äî o que garante custo proporcional ao uso.

---

**SLIDE 7 ‚Äî Pipeline Ass√≠ncrono**

‚ÄúO pipeline ass√≠ncrono √© fundamental para absorver rajadas de carga.

Em um fluxo tradicional do Laravel, n√≥s ter√≠amos um worker long living, rodando continuamente e esperando mensagens chegarem na fila. O problema desse modelo √© que ele fica consumindo CPU mesmo quando n√£o h√° trabalho, o que significa pagar por processamento ocioso e perder elasticidade.

Aqui n√≥s seguimos uma abordagem diferente: a API n√£o processa opera√ß√µes pesadas diretamente ‚Äî ela apenas cria uma tarefa no Cloud Tasks.
O Cloud Tasks funciona no modelo push, enviando cada tarefa via HTTP para os workers em Cloud Run.

Como esses workers s√£o servi√ßos independentes e totalmente gerenciados, o Cloud Run consegue escalar horizontalmente exatamente no ritmo do backlog: quanto mais tarefas chegam, mais inst√¢ncias s√£o criadas; quando n√£o h√° nada para processar, tudo volta a zero, sem custo.

Esse comportamento combina o melhor dos dois mundos: elasticidade real e custo proporcional ao uso, garantindo que o sistema processe picos de tarefas sem travar a API principal e sem manter infraestrutura desnecess√°ria ligada.‚Äù

---

**SLIDE 8 ‚Äî WebSockets + Redis Backplane**

A comunica√ß√£o em tempo real do sistema √© feita pelo Reverb, o servidor de WebSockets do Laravel.

Um ponto importante √© que, diferente de requisi√ß√µes HTTP, conex√µes WebSocket s√£o persistentes: cada inst√¢ncia do Reverb mant√©m seus pr√≥prios clientes conectados em mem√≥ria.
Por isso, n√£o √© poss√≠vel simplesmente ‚Äòescalar horizontalmente‚Äô o servidor de WebSockets sem coordena√ß√£o ‚Äî porque as inst√¢ncias n√£o compartilham estado.

Imagine que um cliente est√° conectado √† inst√¢ncia A e outro √† inst√¢ncia B. Se a inst√¢ncia A receber um evento, a inst√¢ncia B n√£o fica sabendo disso sozinha. O resultado seria um comportamento inconsistente: alguns usu√°rios receberiam eventos e outros n√£o.

Para resolver isso, usamos o Redis como backplane Pub/Sub.
Quando qualquer inst√¢ncia publica um evento, o Redis distribui esse evento para todas as outras inst√¢ncias do Reverb, garantindo que todos os clientes conectados, independentemente de qual inst√¢ncia atenderam, recebam a mesma informa√ß√£o.

Com esse mecanismo, conseguimos escalar WebSockets horizontalmente de forma segura, mantendo consist√™ncia global entre as inst√¢ncias e permitindo que o servi√ßo cres√ßa conforme a demanda sem perder sincroniza√ß√£o em tempo real.‚Äù

---

**SLIDE 9 ‚Äî Metodologia Experimental**

A metodologia √© um **estudo de caso aplicado** sobre uma aplica√ß√£o real.
Eu sigo princ√≠pios de **SRE**, come√ßando pela defini√ß√£o de **SLOs**:

* lat√™ncia P95 menor ou igual a 300 ms;
* taxa de erro menor que 0,5%;
* e disponibilidade maior ou igual a 99,5%.

Toda a infraestrutura √© provisionada com **Terraform**, os ambientes s√£o reproduzidos com Docker e Makefile, e os testes de carga s√£o executados com o **k6**, contra o dom√≠nio real da API.

Foram definidos tr√™s cen√°rios:

1. leitura intensiva,
2. leitura e escrita combinadas,
3. e processamento ass√≠ncrono em larga escala.

---

**SLIDE 10 ‚Äî Resultados: Cen√°rio de Leitura**

No cen√°rio de leitura, simulei at√© **1.000 usu√°rios virtuais**, atingindo picos de quase **970 requisi√ß√µes por segundo**, com m√©dia de 470.
A lat√™ncia P95 ficou em **158 ms**, bem abaixo do SLO, e n√£o houve erros.

  Isso mostra que o caminho de leitura ‚Äî CDN, API, Redis como cache e consultas otimizadas ‚Äî √© extremamente eficiente e escala bem sob carga.

---

**SLIDE 11 ‚Äî Resultados: Escrita/Leitura**

‚ÄúNo cen√°rio misto, cada usu√°rio virtual alternava entre opera√ß√µes de leitura e escrita, simulando de forma mais fiel o comportamento real da aplica√ß√£o.

Com 650 usu√°rios virtuais, o sistema chegou a processar cerca de 540 requisi√ß√µes por segundo antes de come√ßar a violar os SLOs.

Nesse ponto, a lat√™ncia subiu significativamente: o P95 atingiu 658 ms e o P99 chegou a 2,67 segundos, ultrapassando o limite de 300 ms definido como SLO.

A an√°lise detalhada das m√©tricas mostrou que o gargalo n√£o era o banco de dados, mas sim a camada HTTP do Cloud Run, que alcan√ßou o limite de 10 inst√¢ncias imposto pela cota do projeto.

Esse comportamento √© esperado, porque opera√ß√µes de escrita s√£o mais custosas: elas exigem mais CPU, envolvem transa√ß√µes ACID no banco e ainda precisam invalidar cache no Redis.
Assim, o esgotamento da camada de API acontece antes da satura√ß√£o do banco.‚Äù

---

**SLIDE 12 ‚Äî Resultados: Processamento Ass√≠ncrono**

No pipeline ass√≠ncrono, publicamos **51.580 tarefas** no Cloud Tasks.
Em cerca de 10 minutos, todas foram processadas ‚Äî cerca de 86 tarefas por segundo.

Durante esse processo, o Cloud Run escalou automaticamente o n√∫mero de workers enquanto havia fila, e reduziu logo ap√≥s a drenagem.
N√£o houve perda nem duplica√ß√£o de tarefas.
Esse cen√°rio demonstra a **elasticidade real**: o sistema usa recursos apenas quando h√° demanda e volta ao custo m√≠nimo quando o trabalho termina.

---

**SLIDE 13 ‚Äî Conclus√µes**

Os resultados mostram que a arquitetura suporta muito bem workloads intensivos em leitura.
Os limites para escrita vieram diretamente da cota de inst√¢ncias HTTP.
O pipeline ass√≠ncrono demonstrou excelente desempenho e confiabilidade.

E a principal conclus√£o arquitetural √© que o modelo **serverless, el√°stico e pay-per-use** reduz custos em cargas vari√°veis e se adapta a picos sem interven√ß√£o manual.
Esses benef√≠cios se aplicam n√£o s√≥ ao ValorizeAI, mas a **qualquer aplica√ß√£o web moderna com varia√ß√£o de demanda**.

---

**SLIDE 14 ‚Äî Limita√ß√µes e Trabalhos Futuros**

As principais limita√ß√µes do experimento foram as cotas padr√£o do Cloud Run, que limitaram o n√∫mero de inst√¢ncias da API, e o uso de um √∫nico n√≥ do Cloud SQL.
Para trabalhos futuros, propomos repetir os testes com mais vCPUs, adicionar r√©plicas de leitura e evoluir automa√ß√µes e embeddings para casos como detec√ß√£o de anomalias.

---

**SLIDE 15 ‚Äî Refer√™ncias / Encerramento**

Com isso, encerro a apresenta√ß√£o.
Agrade√ßo a aten√ß√£o e fico √† disposi√ß√£o para perguntas.

---

# üéØ **Pronto!**

Essa √© a **vers√£o final, cont√≠nua, fluida e natural**, totalmente alinhada aos seus slides reais e com o tom ideal para banca.

Se quiser, posso te entregar tamb√©m:

‚úÖ **Vers√£o de 10 minutos**
‚úÖ **Vers√£o de 5 minutos** (caso pe√ßam resumo)
‚úÖ **Vers√£o ‚Äúanti-nervosismo‚Äù: frases mais leves e mais curtas**
‚úÖ **Listas de perguntas que a banca provavelmente vai fazer e respostas prontas**

Quer alguma dessas?
